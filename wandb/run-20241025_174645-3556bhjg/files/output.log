Epoch 1 - Training Loss: 0.7102, Validation Loss: 0.6849
Epoch 2 - Training Loss: 0.6784, Validation Loss: 0.6863
Epoch 3 - Training Loss: 0.6774, Validation Loss: 0.6910
Epoch 4 - Training Loss: 0.6963, Validation Loss: 0.6867
Epoch 5 - Training Loss: 0.6863, Validation Loss: 0.6970
Epoch 6 - Training Loss: 0.6951, Validation Loss: 0.6859
Epoch 7 - Training Loss: 0.7032, Validation Loss: 0.6892
Epoch 8 - Training Loss: 0.7209, Validation Loss: 0.6838
Epoch 9 - Training Loss: 0.6866, Validation Loss: 0.6849
Epoch 10 - Training Loss: 0.6952, Validation Loss: 0.6868
Epoch 11 - Training Loss: 0.6932, Validation Loss: 0.6818
Epoch 12 - Training Loss: 0.6669, Validation Loss: 0.6871
Epoch 13 - Training Loss: 0.6827, Validation Loss: 0.6829
Epoch 14 - Training Loss: 0.6933, Validation Loss: 0.6858
Epoch 15 - Training Loss: 0.6837, Validation Loss: 0.6885
Epoch 16 - Training Loss: 0.7021, Validation Loss: 0.6831
Epoch 17 - Training Loss: 0.6994, Validation Loss: 0.6838
Epoch 18 - Training Loss: 0.6897, Validation Loss: 0.6759
Epoch 19 - Training Loss: 0.6726, Validation Loss: 0.6779
Epoch 20 - Training Loss: 0.6902, Validation Loss: 0.6798
Epoch 21 - Training Loss: 0.6650, Validation Loss: 0.6852
Epoch 22 - Training Loss: 0.7017, Validation Loss: 0.6822
Epoch 23 - Training Loss: 0.7103, Validation Loss: 0.6769
Epoch 24 - Training Loss: 0.6991, Validation Loss: 0.6816
Epoch 25 - Training Loss: 0.7080, Validation Loss: 0.6907
Epoch 26 - Training Loss: 0.7003, Validation Loss: 0.6815
Epoch 27 - Training Loss: 0.7008, Validation Loss: 0.6844
Epoch 28 - Training Loss: 0.6911, Validation Loss: 0.6841
Epoch 29 - Training Loss: 0.6726, Validation Loss: 0.6774
Epoch 30 - Training Loss: 0.6817, Validation Loss: 0.6814
Epoch 31 - Training Loss: 0.6733, Validation Loss: 0.6775
Epoch 32 - Training Loss: 0.6919, Validation Loss: 0.6879
Epoch 33 - Training Loss: 0.6964, Validation Loss: 0.6773
Epoch 34 - Training Loss: 0.6982, Validation Loss: 0.6730
Epoch 35 - Training Loss: 0.6701, Validation Loss: 0.6744
Epoch 36 - Training Loss: 0.7006, Validation Loss: 0.6811
Epoch 37 - Training Loss: 0.6886, Validation Loss: 0.6861
Epoch 38 - Training Loss: 0.6742, Validation Loss: 0.6800
Epoch 39 - Training Loss: 0.7015, Validation Loss: 0.6812
Epoch 40 - Training Loss: 0.6826, Validation Loss: 0.6818
Epoch 41 - Training Loss: 0.7090, Validation Loss: 0.6786
Epoch 42 - Training Loss: 0.6732, Validation Loss: 0.6784
Epoch 43 - Training Loss: 0.6818, Validation Loss: 0.6784
Epoch 44 - Training Loss: 0.6898, Validation Loss: 0.6838
Epoch 45 - Training Loss: 0.6893, Validation Loss: 0.6815
Epoch 46 - Training Loss: 0.6908, Validation Loss: 0.6830
Epoch 47 - Training Loss: 0.7000, Validation Loss: 0.6788
Epoch 48 - Training Loss: 0.6718, Validation Loss: 0.6852
Epoch 49 - Training Loss: 0.6905, Validation Loss: 0.6811
Epoch 50 - Training Loss: 0.6904, Validation Loss: 0.6812
Epoch 51 - Training Loss: 0.6982, Validation Loss: 0.6782
Epoch 52 - Training Loss: 0.6903, Validation Loss: 0.6795
Epoch 53 - Training Loss: 0.6909, Validation Loss: 0.6770
Epoch 54 - Training Loss: 0.6807, Validation Loss: 0.6724
Epoch 55 - Training Loss: 0.6793, Validation Loss: 0.6770
Epoch 56 - Training Loss: 0.6812, Validation Loss: 0.6726
Epoch 57 - Training Loss: 0.6985, Validation Loss: 0.6808
Epoch 58 - Training Loss: 0.6858, Validation Loss: 0.6783
Epoch 59 - Training Loss: 0.6991, Validation Loss: 0.6861
Epoch 60 - Training Loss: 0.7070, Validation Loss: 0.6823
Epoch 61 - Training Loss: 0.6976, Validation Loss: 0.6847
Epoch 62 - Training Loss: 0.6795, Validation Loss: 0.6835
Epoch 63 - Training Loss: 0.6845, Validation Loss: 0.6802
Epoch 64 - Training Loss: 0.7030, Validation Loss: 0.6721
Epoch 65 - Training Loss: 0.6843, Validation Loss: 0.6853
Epoch 66 - Training Loss: 0.6834, Validation Loss: 0.6773
Epoch 67 - Training Loss: 0.6873, Validation Loss: 0.6907
Epoch 68 - Training Loss: 0.6716, Validation Loss: 0.6875
Epoch 69 - Training Loss: 0.6999, Validation Loss: 0.6828
Epoch 70 - Training Loss: 0.6986, Validation Loss: 0.6826
Epoch 71 - Training Loss: 0.7082, Validation Loss: 0.6820
Epoch 72 - Training Loss: 0.6714, Validation Loss: 0.6865
Epoch 73 - Training Loss: 0.6897, Validation Loss: 0.6877
Epoch 74 - Training Loss: 0.6895, Validation Loss: 0.6831
Epoch 75 - Training Loss: 0.6876, Validation Loss: 0.6770
Epoch 76 - Training Loss: 0.6853, Validation Loss: 0.6759
Epoch 77 - Training Loss: 0.6965, Validation Loss: 0.6729
Epoch 78 - Training Loss: 0.7052, Validation Loss: 0.6867
Epoch 79 - Training Loss: 0.6947, Validation Loss: 0.6758
Epoch 80 - Training Loss: 0.7087, Validation Loss: 0.6714
Epoch 81 - Training Loss: 0.6829, Validation Loss: 0.6870
Epoch 82 - Training Loss: 0.6796, Validation Loss: 0.6869
Epoch 83 - Training Loss: 0.6526, Validation Loss: 0.6874
Epoch 84 - Training Loss: 0.6742, Validation Loss: 0.6859
Epoch 85 - Training Loss: 0.6666, Validation Loss: 0.6819
Epoch 86 - Training Loss: 0.6817, Validation Loss: 0.6857
Epoch 87 - Training Loss: 0.6910, Validation Loss: 0.6756
Epoch 88 - Training Loss: 0.6790, Validation Loss: 0.6847
Epoch 89 - Training Loss: 0.6785, Validation Loss: 0.6918
Epoch 90 - Training Loss: 0.6925, Validation Loss: 0.6795
Epoch 91 - Training Loss: 0.6724, Validation Loss: 0.6913
Epoch 92 - Training Loss: 0.6599, Validation Loss: 0.6781
Epoch 93 - Training Loss: 0.6720, Validation Loss: 0.6861
Epoch 94 - Training Loss: 0.6938, Validation Loss: 0.6938
Epoch 95 - Training Loss: 0.9050, Validation Loss: 0.9340
Epoch 96 - Training Loss: 0.9305, Validation Loss: 0.9287
Epoch 97 - Training Loss: 0.9305, Validation Loss: 0.9273
Epoch 98 - Training Loss: 0.9089, Validation Loss: 0.9260
Epoch 99 - Training Loss: 0.9137, Validation Loss: 0.9306
Epoch 100 - Training Loss: 0.8778, Validation Loss: 0.9377
Epoch 101 - Training Loss: 0.7484, Validation Loss: 0.6823
Epoch 102 - Training Loss: 0.6947, Validation Loss: 0.6940
Epoch 103 - Training Loss: 0.7116, Validation Loss: 0.6901
Epoch 104 - Training Loss: 0.6948, Validation Loss: 0.6914
Epoch 105 - Training Loss: 0.7039, Validation Loss: 0.6874
Epoch 106 - Training Loss: 0.6856, Validation Loss: 0.6835
Epoch 107 - Training Loss: 0.6948, Validation Loss: 0.6901
Epoch 108 - Training Loss: 0.7026, Validation Loss: 0.6914
Epoch 109 - Training Loss: 0.6931, Validation Loss: 0.6888
Epoch 110 - Training Loss: 0.6932, Validation Loss: 0.6883
Epoch 111 - Training Loss: 0.6748, Validation Loss: 0.6859
Epoch 112 - Training Loss: 0.6844, Validation Loss: 0.6806
Epoch 113 - Training Loss: 0.7110, Validation Loss: 0.6864
Epoch 114 - Training Loss: 0.6844, Validation Loss: 0.6849
Epoch 115 - Training Loss: 0.6897, Validation Loss: 0.6849
Epoch 116 - Training Loss: 0.6726, Validation Loss: 0.6836
Epoch 117 - Training Loss: 0.6903, Validation Loss: 0.6836
Epoch 118 - Training Loss: 0.6896, Validation Loss: 0.6796
Epoch 119 - Training Loss: 0.6987, Validation Loss: 0.6796
Epoch 120 - Training Loss: 0.6999, Validation Loss: 0.6822
Epoch 121 - Training Loss: 0.6895, Validation Loss: 0.6822
Epoch 122 - Training Loss: 0.7066, Validation Loss: 0.6849
Epoch 123 - Training Loss: 0.6987, Validation Loss: 0.6836
Epoch 124 - Training Loss: 0.6909, Validation Loss: 0.6796
Epoch 125 - Training Loss: 0.6973, Validation Loss: 0.6849
Epoch 126 - Training Loss: 0.6805, Validation Loss: 0.6849
Epoch 127 - Training Loss: 0.7000, Validation Loss: 0.6849
Epoch 128 - Training Loss: 0.6999, Validation Loss: 0.6862
Epoch 129 - Training Loss: 0.6806, Validation Loss: 0.6770
Epoch 130 - Training Loss: 0.7000, Validation Loss: 0.6823
Epoch 131 - Training Loss: 0.6896, Validation Loss: 0.6797
Epoch 132 - Training Loss: 0.6883, Validation Loss: 0.6811
Epoch 133 - Training Loss: 0.6907, Validation Loss: 0.6833
Epoch 134 - Training Loss: 0.7065, Validation Loss: 0.6783
Epoch 135 - Training Loss: 0.6896, Validation Loss: 0.6903
Epoch 136 - Training Loss: 0.6635, Validation Loss: 0.6833
Epoch 137 - Training Loss: 0.6806, Validation Loss: 0.6896
Epoch 138 - Training Loss: 0.6790, Validation Loss: 0.6771
Epoch 139 - Training Loss: 0.6791, Validation Loss: 0.6849
Epoch 140 - Training Loss: 0.6974, Validation Loss: 0.6809
Epoch 141 - Training Loss: 0.6861, Validation Loss: 0.6822
Epoch 142 - Training Loss: 0.6937, Validation Loss: 0.6808
Epoch 143 - Training Loss: 0.6735, Validation Loss: 0.6881
Epoch 144 - Training Loss: 0.6838, Validation Loss: 0.6875
Epoch 145 - Training Loss: 0.6895, Validation Loss: 0.6848
Epoch 146 - Training Loss: 0.6805, Validation Loss: 0.6865
Epoch 147 - Training Loss: 0.6815, Validation Loss: 0.6845
Epoch 148 - Training Loss: 0.7086, Validation Loss: 0.6854
Epoch 149 - Training Loss: 0.6794, Validation Loss: 0.6860
Epoch 150 - Training Loss: 0.6974, Validation Loss: 0.6836
Epoch 151 - Training Loss: 0.6794, Validation Loss: 0.6796
Epoch 152 - Training Loss: 0.6972, Validation Loss: 0.6862
Epoch 153 - Training Loss: 0.6974, Validation Loss: 0.6822
Epoch 154 - Training Loss: 0.6709, Validation Loss: 0.6836
Epoch 155 - Training Loss: 0.6878, Validation Loss: 0.6849
Epoch 156 - Training Loss: 0.7121, Validation Loss: 0.6809
Epoch 157 - Training Loss: 0.7063, Validation Loss: 0.6889
Epoch 158 - Training Loss: 0.7027, Validation Loss: 0.6822
Epoch 159 - Training Loss: 0.6779, Validation Loss: 0.6833
Epoch 160 - Training Loss: 0.6686, Validation Loss: 0.6848
Epoch 161 - Training Loss: 0.6856, Validation Loss: 0.6810
Epoch 162 - Training Loss: 0.6778, Validation Loss: 0.6872
Epoch 163 - Training Loss: 0.6862, Validation Loss: 0.6896
Epoch 164 - Training Loss: 0.7004, Validation Loss: 0.6927
Epoch 165 - Training Loss: 0.6641, Validation Loss: 0.6901
Epoch 166 - Training Loss: 0.6883, Validation Loss: 0.6914
Epoch 167 - Training Loss: 0.6903, Validation Loss: 0.6770
Epoch 168 - Training Loss: 0.7140, Validation Loss: 0.6901
Epoch 169 - Training Loss: 0.6734, Validation Loss: 0.6902
Epoch 170 - Training Loss: 0.6900, Validation Loss: 0.6862
Epoch 171 - Training Loss: 0.6883, Validation Loss: 0.6822
Epoch 172 - Training Loss: 0.6727, Validation Loss: 0.6723
Epoch 173 - Training Loss: 0.7026, Validation Loss: 0.6837
Epoch 174 - Training Loss: 0.7051, Validation Loss: 0.6820
Epoch 175 - Training Loss: 0.6732, Validation Loss: 0.6804
Epoch 176 - Training Loss: 0.7085, Validation Loss: 0.6866
Epoch 177 - Training Loss: 0.6764, Validation Loss: 0.6759
Epoch 178 - Training Loss: 0.6948, Validation Loss: 0.6786
Epoch 179 - Training Loss: 0.7064, Validation Loss: 0.6721
Epoch 180 - Training Loss: 0.6607, Validation Loss: 0.6858
Epoch 181 - Training Loss: 0.6503, Validation Loss: 0.6888
Epoch 182 - Training Loss: 0.6728, Validation Loss: 0.6835
Epoch 183 - Training Loss: 0.7039, Validation Loss: 0.6849
Epoch 184 - Training Loss: 0.6883, Validation Loss: 0.6836
Epoch 185 - Training Loss: 0.7068, Validation Loss: 0.6756
Epoch 186 - Training Loss: 0.6806, Validation Loss: 0.6796
Epoch 187 - Training Loss: 0.6621, Validation Loss: 0.6769
Epoch 188 - Training Loss: 0.6896, Validation Loss: 0.6729
Epoch 189 - Training Loss: 0.6791, Validation Loss: 0.6809
Epoch 190 - Training Loss: 0.6896, Validation Loss: 0.6796
Epoch 191 - Training Loss: 0.6883, Validation Loss: 0.6836
Epoch 192 - Training Loss: 0.7068, Validation Loss: 0.6849
Epoch 193 - Training Loss: 0.6896, Validation Loss: 0.6796
Epoch 194 - Training Loss: 0.7078, Validation Loss: 0.6875
Epoch 195 - Training Loss: 0.6870, Validation Loss: 0.6769
Epoch 196 - Training Loss: 0.7169, Validation Loss: 0.6822
Epoch 197 - Training Loss: 0.7091, Validation Loss: 0.6836
Epoch 198 - Training Loss: 0.6895, Validation Loss: 0.6836
Epoch 199 - Training Loss: 0.6791, Validation Loss: 0.6809
Epoch 200 - Training Loss: 0.6882, Validation Loss: 0.6822
Epoch 201 - Training Loss: 0.6869, Validation Loss: 0.6743
Epoch 202 - Training Loss: 0.6972, Validation Loss: 0.6743
Epoch 203 - Training Loss: 0.6987, Validation Loss: 0.6875
Epoch 204 - Training Loss: 0.6674, Validation Loss: 0.6756
Epoch 205 - Training Loss: 0.6856, Validation Loss: 0.6796
Epoch 206 - Training Loss: 0.6783, Validation Loss: 0.6769
Epoch 207 - Training Loss: 0.6701, Validation Loss: 0.6902
Epoch 208 - Training Loss: 0.6766, Validation Loss: 0.6836
Epoch 209 - Training Loss: 0.7075, Validation Loss: 0.6809
Epoch 210 - Training Loss: 0.6948, Validation Loss: 0.6836
Epoch 211 - Training Loss: 0.6869, Validation Loss: 0.6789
Epoch 212 - Training Loss: 0.7139, Validation Loss: 0.6787
Epoch 213 - Training Loss: 0.6836, Validation Loss: 0.6834
Epoch 214 - Training Loss: 0.6796, Validation Loss: 0.6835
Epoch 215 - Training Loss: 0.6587, Validation Loss: 0.6928
Epoch 216 - Training Loss: 0.6661, Validation Loss: 0.6861
Epoch 217 - Training Loss: 0.6606, Validation Loss: 0.6821
Epoch 218 - Training Loss: 0.6792, Validation Loss: 0.6888
Epoch 219 - Training Loss: 0.6701, Validation Loss: 0.6888
Epoch 220 - Training Loss: 0.6414, Validation Loss: 0.6797
Epoch 221 - Training Loss: 0.6712, Validation Loss: 0.6770
Epoch 222 - Training Loss: 0.6691, Validation Loss: 0.6782
Epoch 223 - Training Loss: 0.7806, Validation Loss: 0.9260
Epoch 224 - Training Loss: 0.8687, Validation Loss: 0.9340
Epoch 225 - Training Loss: 0.7518, Validation Loss: 0.6744
Epoch 226 - Training Loss: 0.6830, Validation Loss: 0.6821
Epoch 227 - Training Loss: 0.6622, Validation Loss: 0.6848
Epoch 228 - Training Loss: 0.6832, Validation Loss: 0.6901
Epoch 229 - Training Loss: 0.6740, Validation Loss: 0.6914
Epoch 230 - Training Loss: 0.6845, Validation Loss: 0.6927
Epoch 231 - Training Loss: 0.6752, Validation Loss: 0.6873
Epoch 232 - Training Loss: 0.6780, Validation Loss: 0.6943
Epoch 233 - Training Loss: 0.6642, Validation Loss: 0.6874
Epoch 234 - Training Loss: 0.6838, Validation Loss: 0.6861
Epoch 235 - Training Loss: 0.6650, Validation Loss: 0.6967
Epoch 236 - Training Loss: 0.6747, Validation Loss: 0.6744
Epoch 237 - Training Loss: 0.6767, Validation Loss: 0.5505
Epoch 238 - Training Loss: 0.7090, Validation Loss: 0.6928
Epoch 239 - Training Loss: 0.6844, Validation Loss: 0.6818
Epoch 240 - Training Loss: 0.6947, Validation Loss: 0.6862
Epoch 241 - Training Loss: 0.6974, Validation Loss: 0.6822
Epoch 242 - Training Loss: 0.6866, Validation Loss: 0.6809
Epoch 243 - Training Loss: 0.6778, Validation Loss: 0.6782
Epoch 244 - Training Loss: 0.7237, Validation Loss: 0.6836
Epoch 245 - Training Loss: 0.6870, Validation Loss: 0.6809
Epoch 246 - Training Loss: 0.6886, Validation Loss: 0.6822
Epoch 247 - Training Loss: 0.6775, Validation Loss: 0.6862
Epoch 248 - Training Loss: 0.6957, Validation Loss: 0.6806
Epoch 249 - Training Loss: 0.6766, Validation Loss: 0.6784
Epoch 250 - Training Loss: 0.6661, Validation Loss: 0.6850
Epoch 251 - Training Loss: 0.7065, Validation Loss: 0.6797
Epoch 252 - Training Loss: 0.6777, Validation Loss: 0.6797
Epoch 253 - Training Loss: 0.6692, Validation Loss: 0.6798
Epoch 254 - Training Loss: 0.6724, Validation Loss: 0.6954
Epoch 255 - Training Loss: 0.6726, Validation Loss: 0.6914
Epoch 256 - Training Loss: 0.6813, Validation Loss: 0.6888
Epoch 257 - Training Loss: 0.6640, Validation Loss: 0.6861
Epoch 258 - Training Loss: 0.6816, Validation Loss: 0.6835
Epoch 259 - Training Loss: 0.6897, Validation Loss: 0.6874
Epoch 260 - Training Loss: 0.6935, Validation Loss: 0.6788
Epoch 261 - Training Loss: 0.6911, Validation Loss: 0.6730
Epoch 262 - Training Loss: 0.6746, Validation Loss: 0.6823
Epoch 263 - Training Loss: 0.6694, Validation Loss: 0.6747
Epoch 264 - Training Loss: 0.6635, Validation Loss: 0.6782
Epoch 265 - Training Loss: 0.6622, Validation Loss: 0.6821
Epoch 266 - Training Loss: 0.6870, Validation Loss: 0.6901
Epoch 267 - Training Loss: 0.6649, Validation Loss: 0.6861
Epoch 268 - Training Loss: 0.6847, Validation Loss: 0.6874
Epoch 269 - Training Loss: 0.6828, Validation Loss: 0.6821
Epoch 270 - Training Loss: 0.6570, Validation Loss: 0.6821
Epoch 271 - Training Loss: 0.6626, Validation Loss: 0.6888
Epoch 272 - Training Loss: 0.6589, Validation Loss: 0.6845
Epoch 273 - Training Loss: 0.6726, Validation Loss: 0.6864
Epoch 274 - Training Loss: 0.6778, Validation Loss: 0.6808
Epoch 275 - Training Loss: 0.6752, Validation Loss: 0.6833
Epoch 276 - Training Loss: 0.7052, Validation Loss: 0.6779
Epoch 277 - Training Loss: 0.6674, Validation Loss: 0.6845
Epoch 278 - Training Loss: 0.6857, Validation Loss: 0.6832
Epoch 279 - Training Loss: 0.6857, Validation Loss: 0.6832
Epoch 280 - Training Loss: 0.6957, Validation Loss: 0.6784
Epoch 281 - Training Loss: 0.6661, Validation Loss: 0.6848
Epoch 282 - Training Loss: 0.6935, Validation Loss: 0.6914
Epoch 283 - Training Loss: 0.6895, Validation Loss: 0.6835
Epoch 284 - Training Loss: 0.6975, Validation Loss: 0.6848
Epoch 285 - Training Loss: 0.6843, Validation Loss: 0.6835
Epoch 286 - Training Loss: 0.6765, Validation Loss: 0.6901
Epoch 287 - Training Loss: 0.6700, Validation Loss: 0.6795
Epoch 288 - Training Loss: 0.6792, Validation Loss: 0.6901
Epoch 289 - Training Loss: 0.6973, Validation Loss: 0.6928
Epoch 290 - Training Loss: 0.6785, Validation Loss: 0.6928
Epoch 291 - Training Loss: 0.6752, Validation Loss: 0.6874
Epoch 292 - Training Loss: 0.6870, Validation Loss: 0.6755
Epoch 293 - Training Loss: 0.6873, Validation Loss: 0.6874
Epoch 294 - Training Loss: 0.6665, Validation Loss: 0.6861
Epoch 295 - Training Loss: 0.6781, Validation Loss: 0.6874
Epoch 296 - Training Loss: 0.6857, Validation Loss: 0.6808
Epoch 297 - Training Loss: 0.6778, Validation Loss: 0.6888
Epoch 298 - Training Loss: 0.7077, Validation Loss: 0.6901
Epoch 299 - Training Loss: 0.6792, Validation Loss: 0.6874
Epoch 300 - Training Loss: 0.6622, Validation Loss: 0.6901
Test predictions saved to C:\Users\didsu\code_projects\uni_24\DL\link_dl\_02_homeworks\homework_2\test_predictions_ELU_testing_almost_final.csv
Test predictions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
