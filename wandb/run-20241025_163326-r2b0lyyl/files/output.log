Epoch 1 - Training Loss: 0.7083, Validation Loss: 0.6688
Epoch 2 - Training Loss: 0.6689, Validation Loss: 0.6725
Epoch 3 - Training Loss: 0.6967, Validation Loss: 0.6731
Epoch 4 - Training Loss: 0.6955, Validation Loss: 0.6777
Epoch 5 - Training Loss: 0.7042, Validation Loss: 0.6719
Epoch 6 - Training Loss: 0.6882, Validation Loss: 0.6840
Epoch 7 - Training Loss: 0.6934, Validation Loss: 0.6710
Epoch 8 - Training Loss: 0.6879, Validation Loss: 0.6753
Epoch 9 - Training Loss: 0.6611, Validation Loss: 0.6704
Epoch 10 - Training Loss: 0.6912, Validation Loss: 0.6822
Epoch 11 - Training Loss: 0.6941, Validation Loss: 0.6787
Epoch 12 - Training Loss: 0.6849, Validation Loss: 0.6786
Epoch 13 - Training Loss: 0.6820, Validation Loss: 0.6777
Epoch 14 - Training Loss: 0.6920, Validation Loss: 0.6784
Epoch 15 - Training Loss: 0.6713, Validation Loss: 0.6782
Epoch 16 - Training Loss: 0.6647, Validation Loss: 0.6702
Epoch 17 - Training Loss: 0.6654, Validation Loss: 0.6714
Epoch 18 - Training Loss: 0.6827, Validation Loss: 0.6744
Epoch 19 - Training Loss: 0.6644, Validation Loss: 0.6732
Epoch 20 - Training Loss: 0.6593, Validation Loss: 0.6620
Epoch 21 - Training Loss: 0.6766, Validation Loss: 0.6725
Epoch 22 - Training Loss: 0.6585, Validation Loss: 0.5764
Epoch 23 - Training Loss: 0.6741, Validation Loss: 0.6803
Epoch 24 - Training Loss: 0.6885, Validation Loss: 0.6826
Epoch 25 - Training Loss: 0.6713, Validation Loss: 0.6707
Epoch 26 - Training Loss: 0.6983, Validation Loss: 0.6716
Epoch 27 - Training Loss: 0.6790, Validation Loss: 0.6692
Epoch 28 - Training Loss: 0.6719, Validation Loss: 0.6754
Epoch 29 - Training Loss: 0.6761, Validation Loss: 0.6731
Epoch 30 - Training Loss: 0.6818, Validation Loss: 0.6680
Epoch 31 - Training Loss: 0.7119, Validation Loss: 0.9388
Epoch 32 - Training Loss: 0.8341, Validation Loss: 0.6732
Epoch 33 - Training Loss: 0.6812, Validation Loss: 0.6773
Epoch 34 - Training Loss: 0.6898, Validation Loss: 0.6781
Epoch 35 - Training Loss: 0.7001, Validation Loss: 0.6780
Epoch 36 - Training Loss: 0.6908, Validation Loss: 0.6815
Epoch 37 - Training Loss: 0.6722, Validation Loss: 0.6760
Epoch 38 - Training Loss: 0.6899, Validation Loss: 0.6811
Epoch 39 - Training Loss: 0.6894, Validation Loss: 0.6770
Epoch 40 - Training Loss: 0.6797, Validation Loss: 0.6828
Epoch 41 - Training Loss: 0.6703, Validation Loss: 0.6769
Epoch 42 - Training Loss: 0.6968, Validation Loss: 0.6765
Epoch 43 - Training Loss: 0.7053, Validation Loss: 0.6828
Epoch 44 - Training Loss: 0.6684, Validation Loss: 0.6756
Epoch 45 - Training Loss: 0.6959, Validation Loss: 0.6795
Epoch 46 - Training Loss: 0.6669, Validation Loss: 0.6733
Epoch 47 - Training Loss: 0.6837, Validation Loss: 0.6728
Epoch 48 - Training Loss: 0.6822, Validation Loss: 0.6763
Epoch 49 - Training Loss: 0.6887, Validation Loss: 0.6698
Epoch 50 - Training Loss: 0.7016, Validation Loss: 0.6672
Epoch 51 - Training Loss: 0.6228, Validation Loss: 0.5335
Epoch 52 - Training Loss: 0.5918, Validation Loss: 0.6743
Epoch 53 - Training Loss: 0.6928, Validation Loss: 0.6793
Epoch 54 - Training Loss: 0.6673, Validation Loss: 0.6688
Epoch 55 - Training Loss: 0.6841, Validation Loss: 0.6733
Epoch 56 - Training Loss: 0.6647, Validation Loss: 0.6775
Epoch 57 - Training Loss: 0.6618, Validation Loss: 0.6727
Epoch 58 - Training Loss: 0.6709, Validation Loss: 0.6090
Epoch 59 - Training Loss: 0.5914, Validation Loss: 0.6325
Epoch 60 - Training Loss: 0.6874, Validation Loss: 0.6792
Epoch 61 - Training Loss: 0.6780, Validation Loss: 0.6832
Epoch 62 - Training Loss: 0.6817, Validation Loss: 0.6816
Epoch 63 - Training Loss: 0.7182, Validation Loss: 0.6828
Epoch 64 - Training Loss: 0.6907, Validation Loss: 0.6761
Epoch 65 - Training Loss: 0.6907, Validation Loss: 0.6775
Epoch 66 - Training Loss: 0.6904, Validation Loss: 0.6824
Epoch 67 - Training Loss: 0.6902, Validation Loss: 0.6720
Epoch 68 - Training Loss: 0.6991, Validation Loss: 0.6757
Epoch 69 - Training Loss: 0.6897, Validation Loss: 0.6811
Epoch 70 - Training Loss: 0.6804, Validation Loss: 0.6784
Epoch 71 - Training Loss: 0.6984, Validation Loss: 0.6770
Epoch 72 - Training Loss: 0.6890, Validation Loss: 0.6825
Epoch 73 - Training Loss: 0.7070, Validation Loss: 0.6767
Epoch 74 - Training Loss: 0.6976, Validation Loss: 0.6703
Epoch 75 - Training Loss: 0.7157, Validation Loss: 0.6805
Epoch 76 - Training Loss: 0.6881, Validation Loss: 0.6807
Epoch 77 - Training Loss: 0.6789, Validation Loss: 0.6751
Epoch 78 - Training Loss: 0.6968, Validation Loss: 0.6724
Epoch 79 - Training Loss: 0.6967, Validation Loss: 0.6791
Epoch 80 - Training Loss: 0.6967, Validation Loss: 0.6778
Epoch 81 - Training Loss: 0.6837, Validation Loss: 0.6711
Epoch 82 - Training Loss: 0.6913, Validation Loss: 0.6801
Epoch 83 - Training Loss: 0.6994, Validation Loss: 0.6775
Epoch 84 - Training Loss: 0.6865, Validation Loss: 0.6748
Epoch 85 - Training Loss: 0.6954, Validation Loss: 0.6800
Epoch 86 - Training Loss: 0.6679, Validation Loss: 0.6853
Epoch 87 - Training Loss: 0.6678, Validation Loss: 0.6786
Epoch 88 - Training Loss: 0.6941, Validation Loss: 0.6759
Epoch 89 - Training Loss: 0.6948, Validation Loss: 0.6732
Epoch 90 - Training Loss: 0.6946, Validation Loss: 0.6824
Epoch 91 - Training Loss: 0.6854, Validation Loss: 0.6679
Epoch 92 - Training Loss: 0.6759, Validation Loss: 0.6757
Epoch 93 - Training Loss: 0.6664, Validation Loss: 0.6757
Epoch 94 - Training Loss: 0.7069, Validation Loss: 0.6743
Epoch 95 - Training Loss: 0.6932, Validation Loss: 0.6743
Epoch 96 - Training Loss: 0.6749, Validation Loss: 0.6716
Epoch 97 - Training Loss: 0.6834, Validation Loss: 0.6742
Epoch 98 - Training Loss: 0.7012, Validation Loss: 0.6821
Epoch 99 - Training Loss: 0.7008, Validation Loss: 0.6820
Epoch 100 - Training Loss: 0.6907, Validation Loss: 0.6858
Epoch 101 - Training Loss: 0.6901, Validation Loss: 0.6791
Epoch 102 - Training Loss: 0.6801, Validation Loss: 0.6788
Epoch 103 - Training Loss: 0.6883, Validation Loss: 0.6733
Epoch 104 - Training Loss: 0.6693, Validation Loss: 0.6774
Epoch 105 - Training Loss: 0.6868, Validation Loss: 0.6772
Epoch 106 - Training Loss: 0.6677, Validation Loss: 0.6729
Epoch 107 - Training Loss: 0.6851, Validation Loss: 0.6700
Epoch 108 - Training Loss: 0.6599, Validation Loss: 0.6701
Epoch 109 - Training Loss: 0.6918, Validation Loss: 0.6715
Epoch 110 - Training Loss: 0.6981, Validation Loss: 0.6644
Epoch 111 - Training Loss: 0.6613, Validation Loss: 0.6718
Epoch 112 - Training Loss: 0.6779, Validation Loss: 0.6637
Epoch 113 - Training Loss: 0.6673, Validation Loss: 0.6609
Epoch 114 - Training Loss: 0.6390, Validation Loss: 0.5872
Epoch 115 - Training Loss: 0.6018, Validation Loss: 0.6649
Epoch 116 - Training Loss: 0.6359, Validation Loss: 0.5589
Epoch 117 - Training Loss: 0.5099, Validation Loss: 0.5826
Epoch 118 - Training Loss: 0.5366, Validation Loss: 0.5479
Epoch 119 - Training Loss: 0.5332, Validation Loss: 0.5392
Epoch 120 - Training Loss: 0.5236, Validation Loss: 0.5451
Epoch 121 - Training Loss: 0.5533, Validation Loss: 0.6071
Epoch 122 - Training Loss: 0.5847, Validation Loss: 0.5736
Epoch 123 - Training Loss: 0.5282, Validation Loss: 0.5473
Epoch 124 - Training Loss: 0.5148, Validation Loss: 0.5454
Epoch 125 - Training Loss: 0.5454, Validation Loss: 0.5588
Epoch 126 - Training Loss: 0.5008, Validation Loss: 0.5741
Epoch 127 - Training Loss: 0.5644, Validation Loss: 0.5870
Epoch 128 - Training Loss: 0.5464, Validation Loss: 0.5572
Epoch 129 - Training Loss: 0.5188, Validation Loss: 0.5740
Epoch 130 - Training Loss: 0.5040, Validation Loss: 0.5573
Epoch 131 - Training Loss: 0.5134, Validation Loss: 0.5832
Epoch 132 - Training Loss: 0.6426, Validation Loss: 0.6606
Epoch 133 - Training Loss: 0.6471, Validation Loss: 0.6620
Epoch 134 - Training Loss: 0.6712, Validation Loss: 0.6574
Epoch 135 - Training Loss: 0.6294, Validation Loss: 0.5520
Epoch 136 - Training Loss: 0.5541, Validation Loss: 0.5875
Epoch 137 - Training Loss: 0.5249, Validation Loss: 0.5495
Epoch 138 - Training Loss: 0.5622, Validation Loss: 0.7264
Epoch 139 - Training Loss: 0.5762, Validation Loss: 0.8110
Epoch 140 - Training Loss: 0.6852, Validation Loss: 0.6631
Epoch 141 - Training Loss: 0.6879, Validation Loss: 0.6769
Epoch 142 - Training Loss: 0.6480, Validation Loss: 0.6770
Epoch 143 - Training Loss: 0.6844, Validation Loss: 0.6756
Epoch 144 - Training Loss: 0.6831, Validation Loss: 0.6743
Epoch 145 - Training Loss: 0.6635, Validation Loss: 0.6742
Epoch 146 - Training Loss: 0.6795, Validation Loss: 0.6719
Epoch 147 - Training Loss: 0.6706, Validation Loss: 0.6723
Epoch 148 - Training Loss: 0.6875, Validation Loss: 0.6660
Epoch 149 - Training Loss: 0.6507, Validation Loss: 0.6724
Epoch 150 - Training Loss: 0.6686, Validation Loss: 0.6668
Epoch 151 - Training Loss: 0.6675, Validation Loss: 0.6659
Epoch 152 - Training Loss: 0.6755, Validation Loss: 0.6540
Epoch 153 - Training Loss: 0.6428, Validation Loss: 0.6417
Epoch 154 - Training Loss: 0.6076, Validation Loss: 0.5638
Epoch 155 - Training Loss: 0.5136, Validation Loss: 0.5514
Epoch 156 - Training Loss: 0.4967, Validation Loss: 0.5806
Epoch 157 - Training Loss: 0.6515, Validation Loss: 0.6559
Epoch 158 - Training Loss: 0.6495, Validation Loss: 0.6210
Epoch 159 - Training Loss: 0.5459, Validation Loss: 0.5506
Epoch 160 - Training Loss: 0.5791, Validation Loss: 0.5719
Epoch 161 - Training Loss: 0.5087, Validation Loss: 0.5622
Epoch 162 - Training Loss: 0.4927, Validation Loss: 0.5545
Epoch 163 - Training Loss: 0.5274, Validation Loss: 0.5521
Epoch 164 - Training Loss: 0.5028, Validation Loss: 0.5602
Epoch 165 - Training Loss: 0.5101, Validation Loss: 0.5671
Epoch 166 - Training Loss: 0.5218, Validation Loss: 0.5597
Epoch 167 - Training Loss: 0.5126, Validation Loss: 0.5513
Epoch 168 - Training Loss: 0.5029, Validation Loss: 0.5595
Epoch 169 - Training Loss: 0.5063, Validation Loss: 0.5547
Epoch 170 - Training Loss: 0.5035, Validation Loss: 0.5616
Epoch 171 - Training Loss: 0.5483, Validation Loss: 0.5891
Epoch 172 - Training Loss: 0.5352, Validation Loss: 0.5586
Epoch 173 - Training Loss: 0.5221, Validation Loss: 0.5667
Epoch 174 - Training Loss: 0.4985, Validation Loss: 0.5560
Epoch 175 - Training Loss: 0.5053, Validation Loss: 0.6791
Epoch 176 - Training Loss: 0.6240, Validation Loss: 0.6269
Epoch 177 - Training Loss: 0.6278, Validation Loss: 0.6164
Epoch 178 - Training Loss: 0.5472, Validation Loss: 0.6239
Epoch 179 - Training Loss: 0.5008, Validation Loss: 0.5572
Epoch 180 - Training Loss: 0.5362, Validation Loss: 0.5543
Epoch 181 - Training Loss: 0.5024, Validation Loss: 0.5624
Epoch 182 - Training Loss: 0.5662, Validation Loss: 0.5664
Epoch 183 - Training Loss: 0.5650, Validation Loss: 0.5813
Epoch 184 - Training Loss: 0.5104, Validation Loss: 0.5547
Epoch 185 - Training Loss: 0.5150, Validation Loss: 0.5554
Epoch 186 - Training Loss: 0.5177, Validation Loss: 0.5794
Epoch 187 - Training Loss: 0.5197, Validation Loss: 0.5543
Epoch 188 - Training Loss: 0.4957, Validation Loss: 0.5610
Epoch 189 - Training Loss: 0.5222, Validation Loss: 0.5623
Epoch 190 - Training Loss: 0.5062, Validation Loss: 0.5638
Epoch 191 - Training Loss: 0.5119, Validation Loss: 0.5721
Epoch 192 - Training Loss: 0.5002, Validation Loss: 0.5651
Epoch 193 - Training Loss: 0.5083, Validation Loss: 0.5660
Epoch 194 - Training Loss: 0.4887, Validation Loss: 0.5595
Epoch 195 - Training Loss: 0.5006, Validation Loss: 0.5625
Epoch 196 - Training Loss: 0.5205, Validation Loss: 0.6076
Epoch 197 - Training Loss: 0.6383, Validation Loss: 0.6388
Epoch 198 - Training Loss: 0.6393, Validation Loss: 0.6233
Epoch 199 - Training Loss: 0.5631, Validation Loss: 0.5693
Epoch 200 - Training Loss: 0.5075, Validation Loss: 0.5661
Epoch 201 - Training Loss: 0.5029, Validation Loss: 0.5686
Epoch 202 - Training Loss: 0.5047, Validation Loss: 0.5518
Epoch 203 - Training Loss: 0.6167, Validation Loss: 0.6293
Epoch 204 - Training Loss: 0.5923, Validation Loss: 0.5560
Epoch 205 - Training Loss: 0.5277, Validation Loss: 0.5939
Epoch 206 - Training Loss: 0.5209, Validation Loss: 0.5902
Epoch 207 - Training Loss: 0.5099, Validation Loss: 0.5572
Epoch 208 - Training Loss: 0.5103, Validation Loss: 0.5852
Epoch 209 - Training Loss: 0.5194, Validation Loss: 0.5690
Epoch 210 - Training Loss: 0.5068, Validation Loss: 0.5720
Epoch 211 - Training Loss: 0.4987, Validation Loss: 0.5760
Epoch 212 - Training Loss: 0.4972, Validation Loss: 0.5680
Epoch 213 - Training Loss: 0.4945, Validation Loss: 0.5669
Epoch 214 - Training Loss: 0.4976, Validation Loss: 0.5784
Epoch 215 - Training Loss: 0.5010, Validation Loss: 0.5634
Epoch 216 - Training Loss: 0.5035, Validation Loss: 0.5659
Epoch 217 - Training Loss: 0.4913, Validation Loss: 0.5664
Epoch 218 - Training Loss: 0.4994, Validation Loss: 0.6288
Epoch 219 - Training Loss: 0.5420, Validation Loss: 0.5714
Epoch 220 - Training Loss: 0.4993, Validation Loss: 0.5710
Epoch 221 - Training Loss: 0.4872, Validation Loss: 0.5751
Epoch 222 - Training Loss: 0.5102, Validation Loss: 0.5631
Epoch 223 - Training Loss: 0.5451, Validation Loss: 0.5605
Epoch 224 - Training Loss: 0.5207, Validation Loss: 0.5825
Epoch 225 - Training Loss: 0.5406, Validation Loss: 0.5894
Epoch 226 - Training Loss: 0.7995, Validation Loss: 0.9003
Epoch 227 - Training Loss: 0.8299, Validation Loss: 0.8967
Epoch 228 - Training Loss: 0.8251, Validation Loss: 0.8795
Epoch 229 - Training Loss: 0.7268, Validation Loss: 0.5767
Epoch 230 - Training Loss: 0.5619, Validation Loss: 0.6023
Epoch 231 - Training Loss: 0.5376, Validation Loss: 0.6945
Epoch 232 - Training Loss: 0.5613, Validation Loss: 0.5636
Epoch 233 - Training Loss: 0.5298, Validation Loss: 0.5695
Epoch 234 - Training Loss: 0.5111, Validation Loss: 0.5899
Epoch 235 - Training Loss: 0.4985, Validation Loss: 0.5717
Epoch 236 - Training Loss: 0.4950, Validation Loss: 0.5726
Epoch 237 - Training Loss: 0.4928, Validation Loss: 0.5804
Epoch 238 - Training Loss: 0.4993, Validation Loss: 0.5775
Epoch 239 - Training Loss: 0.4878, Validation Loss: 0.5700
Epoch 240 - Training Loss: 0.5061, Validation Loss: 0.5671
Epoch 241 - Training Loss: 0.4829, Validation Loss: 0.5681
Epoch 242 - Training Loss: 0.5141, Validation Loss: 0.5699
Epoch 243 - Training Loss: 0.5167, Validation Loss: 0.5717
Epoch 244 - Training Loss: 0.4863, Validation Loss: 0.5658
Epoch 245 - Training Loss: 0.4906, Validation Loss: 0.5913
Epoch 246 - Training Loss: 0.4997, Validation Loss: 0.5596
Epoch 247 - Training Loss: 0.5168, Validation Loss: 0.6142
Epoch 248 - Training Loss: 0.5169, Validation Loss: 0.5647
Epoch 249 - Training Loss: 0.5307, Validation Loss: 0.6303
Epoch 250 - Training Loss: 0.5590, Validation Loss: 0.5893
Epoch 251 - Training Loss: 0.6165, Validation Loss: 0.5617
Epoch 252 - Training Loss: 0.5049, Validation Loss: 0.5700
Epoch 253 - Training Loss: 0.4956, Validation Loss: 0.5628
Epoch 254 - Training Loss: 0.5061, Validation Loss: 0.5765
Epoch 255 - Training Loss: 0.4888, Validation Loss: 0.5750
Epoch 256 - Training Loss: 0.4871, Validation Loss: 0.5668
Epoch 257 - Training Loss: 0.5056, Validation Loss: 0.5701
Epoch 258 - Training Loss: 0.4867, Validation Loss: 0.5679
Epoch 259 - Training Loss: 0.4954, Validation Loss: 0.5652
Epoch 260 - Training Loss: 0.5047, Validation Loss: 0.5575
Epoch 261 - Training Loss: 0.4949, Validation Loss: 0.5668
Epoch 262 - Training Loss: 0.5140, Validation Loss: 0.5627
Epoch 263 - Training Loss: 0.4861, Validation Loss: 0.5596
Epoch 264 - Training Loss: 0.4946, Validation Loss: 0.5660
Epoch 265 - Training Loss: 0.4971, Validation Loss: 0.5622
Epoch 266 - Training Loss: 0.4858, Validation Loss: 0.6225
Epoch 267 - Training Loss: 0.4917, Validation Loss: 0.5676
Epoch 268 - Training Loss: 0.4935, Validation Loss: 0.5735
Epoch 269 - Training Loss: 0.4936, Validation Loss: 0.5888
Epoch 270 - Training Loss: 0.5545, Validation Loss: 0.5538
Epoch 271 - Training Loss: 0.5363, Validation Loss: 0.5950
Epoch 272 - Training Loss: 0.5462, Validation Loss: 0.5693
Epoch 273 - Training Loss: 0.5328, Validation Loss: 0.6175
Epoch 274 - Training Loss: 0.5016, Validation Loss: 0.5795
Epoch 275 - Training Loss: 0.4960, Validation Loss: 0.5610
Epoch 276 - Training Loss: 0.5036, Validation Loss: 0.5643
Epoch 277 - Training Loss: 0.5034, Validation Loss: 0.5480
Epoch 278 - Training Loss: 0.5331, Validation Loss: 0.5813
Epoch 279 - Training Loss: 0.5063, Validation Loss: 0.5652
Epoch 280 - Training Loss: 0.5158, Validation Loss: 0.5714
Epoch 281 - Training Loss: 0.4880, Validation Loss: 0.5735
Epoch 282 - Training Loss: 0.5003, Validation Loss: 0.6225
Epoch 283 - Training Loss: 0.6805, Validation Loss: 0.5694
Epoch 284 - Training Loss: 0.6102, Validation Loss: 0.6642
Epoch 285 - Training Loss: 0.6815, Validation Loss: 0.6728
Epoch 286 - Training Loss: 0.6740, Validation Loss: 0.6723
Epoch 287 - Training Loss: 0.6625, Validation Loss: 0.6679
Epoch 288 - Training Loss: 0.6449, Validation Loss: 0.6507
Epoch 289 - Training Loss: 0.6324, Validation Loss: 0.5917
Epoch 290 - Training Loss: 0.5366, Validation Loss: 0.6663
Epoch 291 - Training Loss: 0.4919, Validation Loss: 0.5763
Epoch 292 - Training Loss: 0.5576, Validation Loss: 0.5743
Epoch 293 - Training Loss: 0.4992, Validation Loss: 0.5632
Epoch 294 - Training Loss: 0.4996, Validation Loss: 0.5763
Epoch 295 - Training Loss: 0.4950, Validation Loss: 0.5743
Epoch 296 - Training Loss: 0.5062, Validation Loss: 0.5661
Epoch 297 - Training Loss: 0.5066, Validation Loss: 0.5703
Epoch 298 - Training Loss: 0.5052, Validation Loss: 0.5703
Epoch 299 - Training Loss: 0.4866, Validation Loss: 0.5610
Epoch 300 - Training Loss: 0.4867, Validation Loss: 0.5663
Test predictions saved to C:\Users\didsu\code_projects\uni_24\DL\link_dl\_02_homeworks\homework_2\test_predictions_ELU_testing_almost_final.csv
Test predictions: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]
