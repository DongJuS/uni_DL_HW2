Epoch 1 - Training Loss: 0.7086, Validation Loss: 0.7042
Epoch 2 - Training Loss: 0.6937, Validation Loss: 0.7016
Epoch 3 - Training Loss: 0.7023, Validation Loss: 0.7094
Epoch 4 - Training Loss: 0.6840, Validation Loss: 0.7077
Epoch 5 - Training Loss: 0.6916, Validation Loss: 0.7054
Epoch 6 - Training Loss: 0.6914, Validation Loss: 0.7046
Epoch 7 - Training Loss: 0.7078, Validation Loss: 0.6990
Epoch 8 - Training Loss: 0.6900, Validation Loss: 0.6987
Epoch 9 - Training Loss: 0.6907, Validation Loss: 0.6924
Epoch 10 - Training Loss: 0.6997, Validation Loss: 0.7028
Epoch 11 - Training Loss: 0.6912, Validation Loss: 0.6954
Epoch 12 - Training Loss: 0.6709, Validation Loss: 0.6956
Epoch 13 - Training Loss: 0.7892, Validation Loss: 0.9253
Epoch 14 - Training Loss: 0.8123, Validation Loss: 0.7048
Epoch 15 - Training Loss: 0.7005, Validation Loss: 0.7057
Epoch 16 - Training Loss: 0.6842, Validation Loss: 0.6991
Epoch 17 - Training Loss: 0.7018, Validation Loss: 0.7004
Epoch 18 - Training Loss: 0.7108, Validation Loss: 0.6991
Epoch 19 - Training Loss: 0.6828, Validation Loss: 0.7070
Epoch 20 - Training Loss: 0.6821, Validation Loss: 0.7070
Epoch 21 - Training Loss: 0.6732, Validation Loss: 0.7057
Epoch 22 - Training Loss: 0.7001, Validation Loss: 0.7030
Epoch 23 - Training Loss: 0.6638, Validation Loss: 0.6990
Epoch 24 - Training Loss: 0.7092, Validation Loss: 0.7110
Epoch 25 - Training Loss: 0.7001, Validation Loss: 0.6990
Epoch 26 - Training Loss: 0.6819, Validation Loss: 0.7083
Epoch 27 - Training Loss: 0.7275, Validation Loss: 0.7057
Epoch 28 - Training Loss: 0.6820, Validation Loss: 0.7123
Epoch 29 - Training Loss: 0.6909, Validation Loss: 0.7030
Epoch 30 - Training Loss: 0.6818, Validation Loss: 0.7043
Epoch 31 - Training Loss: 0.6819, Validation Loss: 0.7082
Epoch 32 - Training Loss: 0.7000, Validation Loss: 0.7069
Epoch 33 - Training Loss: 0.6909, Validation Loss: 0.7082
Epoch 34 - Training Loss: 0.6819, Validation Loss: 0.7015
Epoch 35 - Training Loss: 0.6907, Validation Loss: 0.6948
Epoch 36 - Training Loss: 0.6999, Validation Loss: 0.6999
Epoch 37 - Training Loss: 0.7000, Validation Loss: 0.7010
Epoch 38 - Training Loss: 0.6904, Validation Loss: 0.6988
Epoch 39 - Training Loss: 0.6802, Validation Loss: 0.7030
Epoch 40 - Training Loss: 0.6810, Validation Loss: 0.6941
Epoch 41 - Training Loss: 0.6715, Validation Loss: 0.6958
Epoch 42 - Training Loss: 0.6723, Validation Loss: 0.6901
Epoch 43 - Training Loss: 0.6581, Validation Loss: 0.6981
Epoch 44 - Training Loss: 0.6997, Validation Loss: 0.6890
Epoch 45 - Training Loss: 0.6809, Validation Loss: 0.6914
Epoch 46 - Training Loss: 0.7071, Validation Loss: 0.6940
Epoch 47 - Training Loss: 0.6949, Validation Loss: 0.6940
Epoch 48 - Training Loss: 0.6929, Validation Loss: 0.6943
Epoch 49 - Training Loss: 0.6793, Validation Loss: 0.6898
Epoch 50 - Training Loss: 0.7139, Validation Loss: 0.6955
Epoch 51 - Training Loss: 0.6866, Validation Loss: 0.6918
Epoch 52 - Training Loss: 0.6789, Validation Loss: 0.6937
Epoch 53 - Training Loss: 0.6828, Validation Loss: 0.7016
Epoch 54 - Training Loss: 0.7066, Validation Loss: 0.6864
Epoch 55 - Training Loss: 0.7254, Validation Loss: 0.6927
Epoch 56 - Training Loss: 0.6795, Validation Loss: 0.6940
Epoch 57 - Training Loss: 0.6777, Validation Loss: 0.6927
Epoch 58 - Training Loss: 0.6866, Validation Loss: 0.6927
Epoch 59 - Training Loss: 0.6803, Validation Loss: 0.6913
Epoch 60 - Training Loss: 0.6808, Validation Loss: 0.6953
Epoch 61 - Training Loss: 0.7053, Validation Loss: 0.6940
Epoch 62 - Training Loss: 0.6985, Validation Loss: 0.6874
Epoch 63 - Training Loss: 0.6886, Validation Loss: 0.6901
Epoch 64 - Training Loss: 0.6900, Validation Loss: 0.6914
Epoch 65 - Training Loss: 0.6974, Validation Loss: 0.6860
Epoch 66 - Training Loss: 0.6779, Validation Loss: 0.6940
Epoch 67 - Training Loss: 0.6675, Validation Loss: 0.6980
Epoch 68 - Training Loss: 0.6971, Validation Loss: 0.6887
Epoch 69 - Training Loss: 0.6988, Validation Loss: 0.6980
Epoch 70 - Training Loss: 0.6862, Validation Loss: 0.6967
Epoch 71 - Training Loss: 0.6795, Validation Loss: 0.6993
Epoch 72 - Training Loss: 0.6973, Validation Loss: 0.6914
Epoch 73 - Training Loss: 0.6907, Validation Loss: 0.6954
Epoch 74 - Training Loss: 0.6867, Validation Loss: 0.6993
Epoch 75 - Training Loss: 0.6995, Validation Loss: 0.6962
Epoch 76 - Training Loss: 0.7068, Validation Loss: 0.7124
Epoch 77 - Training Loss: 0.7017, Validation Loss: 0.6920
Epoch 78 - Training Loss: 0.7256, Validation Loss: 0.6978
Epoch 79 - Training Loss: 0.6861, Validation Loss: 0.6961
Epoch 80 - Training Loss: 0.6579, Validation Loss: 0.6950
Epoch 81 - Training Loss: 0.6938, Validation Loss: 0.6932
Epoch 82 - Training Loss: 0.6965, Validation Loss: 0.6960
Epoch 83 - Training Loss: 0.6961, Validation Loss: 0.6949
Epoch 84 - Training Loss: 0.6869, Validation Loss: 0.7008
Epoch 85 - Training Loss: 0.6877, Validation Loss: 0.6916
Epoch 86 - Training Loss: 0.6705, Validation Loss: 0.6983
Epoch 87 - Training Loss: 0.7037, Validation Loss: 0.6973
Epoch 88 - Training Loss: 0.6873, Validation Loss: 0.6942
Epoch 89 - Training Loss: 0.6948, Validation Loss: 0.6949
Epoch 90 - Training Loss: 0.6958, Validation Loss: 0.7045
Epoch 91 - Training Loss: 0.6762, Validation Loss: 0.6948
Epoch 92 - Training Loss: 0.6884, Validation Loss: 0.6974
Epoch 93 - Training Loss: 0.6855, Validation Loss: 0.7057
Epoch 94 - Training Loss: 0.7047, Validation Loss: 0.6951
Epoch 95 - Training Loss: 0.6679, Validation Loss: 0.7004
Epoch 96 - Training Loss: 0.6837, Validation Loss: 0.6911
Epoch 97 - Training Loss: 0.6736, Validation Loss: 0.7016
Epoch 98 - Training Loss: 0.6839, Validation Loss: 0.6925
Epoch 99 - Training Loss: 0.7014, Validation Loss: 0.6939
Epoch 100 - Training Loss: 0.6936, Validation Loss: 0.6951
Epoch 101 - Training Loss: 0.6542, Validation Loss: 0.7005
Epoch 102 - Training Loss: 0.6820, Validation Loss: 0.6955
Epoch 103 - Training Loss: 0.7112, Validation Loss: 0.6976
Epoch 104 - Training Loss: 0.6759, Validation Loss: 0.6976
Epoch 105 - Training Loss: 0.6828, Validation Loss: 0.6998
Epoch 106 - Training Loss: 0.6823, Validation Loss: 0.7004
Epoch 107 - Training Loss: 0.6674, Validation Loss: 0.6925
Epoch 108 - Training Loss: 0.7115, Validation Loss: 0.6964
Epoch 109 - Training Loss: 0.7044, Validation Loss: 0.6852
Epoch 110 - Training Loss: 0.7162, Validation Loss: 0.6993
Epoch 111 - Training Loss: 0.6779, Validation Loss: 0.6962
Epoch 112 - Training Loss: 0.6848, Validation Loss: 0.6913
Epoch 113 - Training Loss: 0.6723, Validation Loss: 0.6945
Epoch 114 - Training Loss: 0.6825, Validation Loss: 0.6923
Epoch 115 - Training Loss: 0.6806, Validation Loss: 0.7001
Epoch 116 - Training Loss: 0.6868, Validation Loss: 0.6972
Epoch 117 - Training Loss: 0.6742, Validation Loss: 0.6961
Epoch 118 - Training Loss: 0.6921, Validation Loss: 0.6916
Epoch 119 - Training Loss: 0.6986, Validation Loss: 0.7078
Epoch 120 - Training Loss: 0.7188, Validation Loss: 0.6925
Epoch 121 - Training Loss: 0.6805, Validation Loss: 0.7056
Epoch 122 - Training Loss: 0.6927, Validation Loss: 0.6967
Epoch 123 - Training Loss: 0.6772, Validation Loss: 0.6955
Epoch 124 - Training Loss: 0.6796, Validation Loss: 0.6941
Epoch 125 - Training Loss: 0.6875, Validation Loss: 0.6954
Epoch 126 - Training Loss: 0.7059, Validation Loss: 0.6913
Epoch 127 - Training Loss: 0.6804, Validation Loss: 0.6980
Epoch 128 - Training Loss: 0.6780, Validation Loss: 0.6980
Epoch 129 - Training Loss: 0.6961, Validation Loss: 0.6913
Epoch 130 - Training Loss: 0.6899, Validation Loss: 0.6940
Epoch 131 - Training Loss: 0.6789, Validation Loss: 0.6900
Epoch 132 - Training Loss: 0.6783, Validation Loss: 0.6953
Epoch 133 - Training Loss: 0.6675, Validation Loss: 0.6940
Epoch 134 - Training Loss: 0.7041, Validation Loss: 0.6953
Epoch 135 - Training Loss: 0.6763, Validation Loss: 0.6940
Epoch 136 - Training Loss: 0.6786, Validation Loss: 0.6913
Epoch 137 - Training Loss: 0.7135, Validation Loss: 0.6918
Epoch 138 - Training Loss: 0.7015, Validation Loss: 0.6999
Epoch 139 - Training Loss: 0.6779, Validation Loss: 0.7015
Epoch 140 - Training Loss: 0.6669, Validation Loss: 0.6965
Epoch 141 - Training Loss: 0.6764, Validation Loss: 0.6899
Epoch 142 - Training Loss: 0.7039, Validation Loss: 0.7005
Epoch 143 - Training Loss: 0.7131, Validation Loss: 0.6965
Epoch 144 - Training Loss: 0.6950, Validation Loss: 0.6992
Epoch 145 - Training Loss: 0.6747, Validation Loss: 0.6979
Epoch 146 - Training Loss: 0.6766, Validation Loss: 0.6952
Epoch 147 - Training Loss: 0.6538, Validation Loss: 0.6962
Epoch 148 - Training Loss: 0.6934, Validation Loss: 0.6986
Epoch 149 - Training Loss: 0.6930, Validation Loss: 0.6990
Epoch 150 - Training Loss: 0.6730, Validation Loss: 0.6929
Epoch 151 - Training Loss: 0.6523, Validation Loss: 0.6769
Epoch 152 - Training Loss: 0.8632, Validation Loss: 0.9184
Epoch 153 - Training Loss: 0.9396, Validation Loss: 0.9186
Epoch 154 - Training Loss: 0.9122, Validation Loss: 0.9277
Epoch 155 - Training Loss: 0.9213, Validation Loss: 0.9224
Epoch 156 - Training Loss: 0.9304, Validation Loss: 0.9183
Epoch 157 - Training Loss: 0.9391, Validation Loss: 0.9210
Epoch 158 - Training Loss: 0.9107, Validation Loss: 0.9159
Epoch 159 - Training Loss: 0.9291, Validation Loss: 0.9157
Epoch 160 - Training Loss: 0.9116, Validation Loss: 0.9129
Epoch 161 - Training Loss: 0.9383, Validation Loss: 0.9169
Epoch 162 - Training Loss: 0.9460, Validation Loss: 0.9182
Epoch 163 - Training Loss: 0.9369, Validation Loss: 0.9169
Epoch 164 - Training Loss: 0.9366, Validation Loss: 0.9196
Epoch 165 - Training Loss: 0.9357, Validation Loss: 0.9129
Epoch 166 - Training Loss: 0.9265, Validation Loss: 0.9143
Epoch 167 - Training Loss: 0.9265, Validation Loss: 0.9156
Epoch 168 - Training Loss: 0.9265, Validation Loss: 0.9196
Epoch 169 - Training Loss: 0.9173, Validation Loss: 0.9169
Epoch 170 - Training Loss: 0.9447, Validation Loss: 0.9143
Epoch 171 - Training Loss: 0.9253, Validation Loss: 0.9156
Epoch 172 - Training Loss: 0.9228, Validation Loss: 0.9209
Epoch 173 - Training Loss: 0.9279, Validation Loss: 0.9169
Epoch 174 - Training Loss: 0.9370, Validation Loss: 0.9129
Epoch 175 - Training Loss: 0.9278, Validation Loss: 0.9209
Epoch 176 - Training Loss: 0.9356, Validation Loss: 0.9143
Epoch 177 - Training Loss: 0.9360, Validation Loss: 0.9143
Epoch 178 - Training Loss: 0.9448, Validation Loss: 0.9182
Epoch 179 - Training Loss: 0.9265, Validation Loss: 0.9222
Epoch 180 - Training Loss: 0.9265, Validation Loss: 0.9156
Epoch 181 - Training Loss: 0.9266, Validation Loss: 0.9169
Epoch 182 - Training Loss: 0.9269, Validation Loss: 0.9156
Epoch 183 - Training Loss: 0.9261, Validation Loss: 0.9143
Epoch 184 - Training Loss: 0.9161, Validation Loss: 0.9129
Epoch 185 - Training Loss: 0.9074, Validation Loss: 0.9222
Epoch 186 - Training Loss: 0.9333, Validation Loss: 0.9116
Epoch 187 - Training Loss: 0.9435, Validation Loss: 0.9156
Epoch 188 - Training Loss: 0.9432, Validation Loss: 0.9196
Epoch 189 - Training Loss: 0.9066, Validation Loss: 0.9156
Epoch 190 - Training Loss: 0.8940, Validation Loss: 0.9116
Epoch 191 - Training Loss: 0.9239, Validation Loss: 0.9156
Epoch 192 - Training Loss: 0.9166, Validation Loss: 0.9209
Epoch 193 - Training Loss: 0.9297, Validation Loss: 0.9169
Epoch 194 - Training Loss: 0.8494, Validation Loss: 0.6872
Epoch 195 - Training Loss: 0.7017, Validation Loss: 0.6965
Epoch 196 - Training Loss: 0.7000, Validation Loss: 0.6979
Epoch 197 - Training Loss: 0.6818, Validation Loss: 0.6953
Epoch 198 - Training Loss: 0.7090, Validation Loss: 0.7020
Epoch 199 - Training Loss: 0.6909, Validation Loss: 0.6993
Epoch 200 - Training Loss: 0.6818, Validation Loss: 0.7020
Epoch 201 - Training Loss: 0.7091, Validation Loss: 0.7033
Epoch 202 - Training Loss: 0.6726, Validation Loss: 0.7033
Epoch 203 - Training Loss: 0.7000, Validation Loss: 0.6980
Epoch 204 - Training Loss: 0.7000, Validation Loss: 0.7006
Epoch 205 - Training Loss: 0.6909, Validation Loss: 0.6927
Epoch 206 - Training Loss: 0.6722, Validation Loss: 0.7032
Epoch 207 - Training Loss: 0.6909, Validation Loss: 0.7032
Epoch 208 - Training Loss: 0.7000, Validation Loss: 0.6952
Epoch 209 - Training Loss: 0.6818, Validation Loss: 0.6952
Epoch 210 - Training Loss: 0.6817, Validation Loss: 0.7019
Epoch 211 - Training Loss: 0.6726, Validation Loss: 0.6979
Epoch 212 - Training Loss: 0.6992, Validation Loss: 0.6992
Epoch 213 - Training Loss: 0.6896, Validation Loss: 0.7005
Epoch 214 - Training Loss: 0.7000, Validation Loss: 0.6979
Epoch 215 - Training Loss: 0.7000, Validation Loss: 0.6979
Epoch 216 - Training Loss: 0.7086, Validation Loss: 0.7005
Epoch 217 - Training Loss: 0.6896, Validation Loss: 0.6992
Epoch 218 - Training Loss: 0.6896, Validation Loss: 0.7045
Epoch 219 - Training Loss: 0.6896, Validation Loss: 0.7005
Epoch 220 - Training Loss: 0.6816, Validation Loss: 0.7005
Epoch 221 - Training Loss: 0.6713, Validation Loss: 0.6992
Epoch 222 - Training Loss: 0.6713, Validation Loss: 0.6979
Epoch 223 - Training Loss: 0.6909, Validation Loss: 0.7032
Epoch 224 - Training Loss: 0.6804, Validation Loss: 0.6939
Epoch 225 - Training Loss: 0.6817, Validation Loss: 0.7032
Epoch 226 - Training Loss: 0.6883, Validation Loss: 0.6979
Epoch 227 - Training Loss: 0.6804, Validation Loss: 0.6979
Epoch 228 - Training Loss: 0.6987, Validation Loss: 0.6952
Epoch 229 - Training Loss: 0.6700, Validation Loss: 0.6979
Epoch 230 - Training Loss: 0.6713, Validation Loss: 0.7058
Epoch 231 - Training Loss: 0.6987, Validation Loss: 0.6965
Epoch 232 - Training Loss: 0.7091, Validation Loss: 0.6979
Epoch 233 - Training Loss: 0.7169, Validation Loss: 0.6939
Epoch 234 - Training Loss: 0.6719, Validation Loss: 0.6965
Epoch 235 - Training Loss: 0.7080, Validation Loss: 0.6992
Epoch 236 - Training Loss: 0.6896, Validation Loss: 0.6992
Epoch 237 - Training Loss: 0.6713, Validation Loss: 0.6952
Epoch 238 - Training Loss: 0.6804, Validation Loss: 0.7045
Epoch 239 - Training Loss: 0.7065, Validation Loss: 0.6952
Epoch 240 - Training Loss: 0.6987, Validation Loss: 0.6965
Epoch 241 - Training Loss: 0.6804, Validation Loss: 0.6979
Epoch 242 - Training Loss: 0.6987, Validation Loss: 0.6965
Epoch 243 - Training Loss: 0.6804, Validation Loss: 0.7018
Epoch 244 - Training Loss: 0.6791, Validation Loss: 0.7018
Epoch 245 - Training Loss: 0.6896, Validation Loss: 0.6992
Epoch 246 - Training Loss: 0.6622, Validation Loss: 0.7032
Epoch 247 - Training Loss: 0.6883, Validation Loss: 0.6899
Epoch 248 - Training Loss: 0.6713, Validation Loss: 0.6992
Epoch 249 - Training Loss: 0.6896, Validation Loss: 0.7005
Epoch 250 - Training Loss: 0.6896, Validation Loss: 0.6872
Epoch 251 - Training Loss: 0.6791, Validation Loss: 0.6939
Epoch 252 - Training Loss: 0.6974, Validation Loss: 0.6992
Epoch 253 - Training Loss: 0.6628, Validation Loss: 0.6965
Epoch 254 - Training Loss: 0.6804, Validation Loss: 0.7005
Epoch 255 - Training Loss: 0.6883, Validation Loss: 0.6965
Epoch 256 - Training Loss: 0.6804, Validation Loss: 0.6979
Epoch 257 - Training Loss: 0.7065, Validation Loss: 0.6939
Epoch 258 - Training Loss: 0.7078, Validation Loss: 0.6926
Epoch 259 - Training Loss: 0.6890, Validation Loss: 0.7005
Epoch 260 - Training Loss: 0.6883, Validation Loss: 0.6965
Epoch 261 - Training Loss: 0.6973, Validation Loss: 0.6978
Epoch 262 - Training Loss: 0.6894, Validation Loss: 0.6936
Epoch 263 - Training Loss: 0.6791, Validation Loss: 0.6971
Epoch 264 - Training Loss: 0.7065, Validation Loss: 0.6994
Epoch 265 - Training Loss: 0.6883, Validation Loss: 0.6941
Epoch 266 - Training Loss: 0.6700, Validation Loss: 0.6981
Epoch 267 - Training Loss: 0.6802, Validation Loss: 0.6964
Epoch 268 - Training Loss: 0.6974, Validation Loss: 0.6939
Epoch 269 - Training Loss: 0.6883, Validation Loss: 0.6992
Epoch 270 - Training Loss: 0.7065, Validation Loss: 0.6952
Epoch 271 - Training Loss: 0.6883, Validation Loss: 0.7018
Epoch 272 - Training Loss: 0.6883, Validation Loss: 0.7045
Epoch 273 - Training Loss: 0.6791, Validation Loss: 0.7018
Epoch 274 - Training Loss: 0.6883, Validation Loss: 0.6992
Epoch 275 - Training Loss: 0.6791, Validation Loss: 0.6939
Epoch 276 - Training Loss: 0.6883, Validation Loss: 0.7045
Epoch 277 - Training Loss: 0.6883, Validation Loss: 0.6952
Epoch 278 - Training Loss: 0.7052, Validation Loss: 0.6939
Epoch 279 - Training Loss: 0.6974, Validation Loss: 0.6939
Epoch 280 - Training Loss: 0.6974, Validation Loss: 0.7005
Epoch 281 - Training Loss: 0.6791, Validation Loss: 0.7005
Epoch 282 - Training Loss: 0.7156, Validation Loss: 0.7005
Epoch 283 - Training Loss: 0.7157, Validation Loss: 0.7031
Epoch 284 - Training Loss: 0.6883, Validation Loss: 0.7045
Epoch 285 - Training Loss: 0.6609, Validation Loss: 0.7018
Epoch 286 - Training Loss: 0.6700, Validation Loss: 0.6951
Epoch 287 - Training Loss: 0.6776, Validation Loss: 0.6965
Epoch 288 - Training Loss: 0.6791, Validation Loss: 0.6895
Epoch 289 - Training Loss: 0.6792, Validation Loss: 0.6948
Epoch 290 - Training Loss: 0.6690, Validation Loss: 0.6928
Epoch 291 - Training Loss: 0.6791, Validation Loss: 0.6966
Epoch 292 - Training Loss: 0.6963, Validation Loss: 0.6993
Epoch 293 - Training Loss: 0.6872, Validation Loss: 0.6969
Epoch 294 - Training Loss: 0.7052, Validation Loss: 0.6940
Epoch 295 - Training Loss: 0.6870, Validation Loss: 0.6977
Epoch 296 - Training Loss: 0.6961, Validation Loss: 0.7002
Epoch 297 - Training Loss: 0.6779, Validation Loss: 0.6998
Epoch 298 - Training Loss: 0.6883, Validation Loss: 0.6974
Epoch 299 - Training Loss: 0.6596, Validation Loss: 0.6931
Epoch 300 - Training Loss: 0.6873, Validation Loss: 0.6887
Test predictions saved to C:\Users\didsu\code_projects\uni_24\DL\link_dl\_02_homeworks\homework_2\test_predictions_ELU_testing_almost_final.csv
Test predictions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
