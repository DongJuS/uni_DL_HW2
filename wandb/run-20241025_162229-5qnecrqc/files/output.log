Epoch 1 - Training Loss: 0.7070, Validation Loss: 0.7000
Epoch 2 - Training Loss: 0.7104, Validation Loss: 0.6898
Epoch 3 - Training Loss: 0.6786, Validation Loss: 0.6942
Epoch 4 - Training Loss: 0.7008, Validation Loss: 0.6930
Epoch 5 - Training Loss: 0.6905, Validation Loss: 0.7018
Epoch 6 - Training Loss: 0.6977, Validation Loss: 0.7016
Epoch 7 - Training Loss: 0.6882, Validation Loss: 0.6681
Epoch 8 - Training Loss: 0.6831, Validation Loss: 0.6978
Epoch 9 - Training Loss: 0.7161, Validation Loss: 0.6958
Epoch 10 - Training Loss: 0.6909, Validation Loss: 0.6919
Epoch 11 - Training Loss: 0.6591, Validation Loss: 0.6888
Epoch 12 - Training Loss: 0.6906, Validation Loss: 0.6940
Epoch 13 - Training Loss: 0.6947, Validation Loss: 0.6945
Epoch 14 - Training Loss: 0.6917, Validation Loss: 0.6976
Epoch 15 - Training Loss: 0.7097, Validation Loss: 0.6843
Epoch 16 - Training Loss: 0.6824, Validation Loss: 0.6918
Epoch 17 - Training Loss: 0.6904, Validation Loss: 0.6912
Epoch 18 - Training Loss: 0.6894, Validation Loss: 0.6959
Epoch 19 - Training Loss: 0.6971, Validation Loss: 0.6910
Epoch 20 - Training Loss: 0.6853, Validation Loss: 0.6936
Epoch 21 - Training Loss: 0.6822, Validation Loss: 0.6964
Epoch 22 - Training Loss: 0.7011, Validation Loss: 0.6905
Epoch 23 - Training Loss: 0.6791, Validation Loss: 0.6931
Epoch 24 - Training Loss: 0.6975, Validation Loss: 0.6854
Epoch 25 - Training Loss: 0.6789, Validation Loss: 0.6936
Epoch 26 - Training Loss: 0.6782, Validation Loss: 0.6878
Epoch 27 - Training Loss: 0.6684, Validation Loss: 0.6972
Epoch 28 - Training Loss: 0.6858, Validation Loss: 0.6911
Epoch 29 - Training Loss: 0.6755, Validation Loss: 0.6951
Epoch 30 - Training Loss: 0.6644, Validation Loss: 0.6946
Epoch 31 - Training Loss: 0.6852, Validation Loss: 0.7007
Epoch 32 - Training Loss: 0.6716, Validation Loss: 0.6901
Epoch 33 - Training Loss: 0.6571, Validation Loss: 0.6875
Epoch 34 - Training Loss: 0.8661, Validation Loss: 0.9028
Epoch 35 - Training Loss: 0.7342, Validation Loss: 0.6940
Epoch 36 - Training Loss: 0.6903, Validation Loss: 0.6915
Epoch 37 - Training Loss: 0.6926, Validation Loss: 0.6896
Epoch 38 - Training Loss: 0.6739, Validation Loss: 0.6923
Epoch 39 - Training Loss: 0.6921, Validation Loss: 0.6936
Epoch 40 - Training Loss: 0.7011, Validation Loss: 0.6869
Epoch 41 - Training Loss: 0.6737, Validation Loss: 0.6890
Epoch 42 - Training Loss: 0.6827, Validation Loss: 0.6929
Epoch 43 - Training Loss: 0.7008, Validation Loss: 0.6892
Epoch 44 - Training Loss: 0.7006, Validation Loss: 0.6930
Epoch 45 - Training Loss: 0.6640, Validation Loss: 0.6931
Epoch 46 - Training Loss: 0.7095, Validation Loss: 0.6949
Epoch 47 - Training Loss: 0.6729, Validation Loss: 0.6862
Epoch 48 - Training Loss: 0.7001, Validation Loss: 0.6893
Epoch 49 - Training Loss: 0.6908, Validation Loss: 0.6924
Epoch 50 - Training Loss: 0.6998, Validation Loss: 0.6949
Epoch 51 - Training Loss: 0.7088, Validation Loss: 0.6869
Epoch 52 - Training Loss: 0.6905, Validation Loss: 0.6921
Epoch 53 - Training Loss: 0.6995, Validation Loss: 0.6945
Epoch 54 - Training Loss: 0.6811, Validation Loss: 0.6931
Epoch 55 - Training Loss: 0.6991, Validation Loss: 0.6916
Epoch 56 - Training Loss: 0.6900, Validation Loss: 0.6875
Epoch 57 - Training Loss: 0.6990, Validation Loss: 0.6886
Epoch 58 - Training Loss: 0.6989, Validation Loss: 0.6950
Epoch 59 - Training Loss: 0.6896, Validation Loss: 0.6896
Epoch 60 - Training Loss: 0.6897, Validation Loss: 0.6965
Epoch 61 - Training Loss: 0.6892, Validation Loss: 0.6920
Epoch 62 - Training Loss: 0.6981, Validation Loss: 0.6985
Epoch 63 - Training Loss: 0.6888, Validation Loss: 0.6866
Epoch 64 - Training Loss: 0.6929, Validation Loss: 0.6836
Epoch 65 - Training Loss: 0.6905, Validation Loss: 0.6875
Epoch 66 - Training Loss: 0.6783, Validation Loss: 0.6914
Epoch 67 - Training Loss: 0.7050, Validation Loss: 0.6940
Epoch 68 - Training Loss: 0.6942, Validation Loss: 0.6873
Epoch 69 - Training Loss: 0.6864, Validation Loss: 0.6900
Epoch 70 - Training Loss: 0.7130, Validation Loss: 0.6875
Epoch 71 - Training Loss: 0.6669, Validation Loss: 0.6822
Epoch 72 - Training Loss: 0.6663, Validation Loss: 0.6916
Epoch 73 - Training Loss: 0.6749, Validation Loss: 0.6902
Epoch 74 - Training Loss: 0.6832, Validation Loss: 0.6863
Epoch 75 - Training Loss: 0.6913, Validation Loss: 0.6825
Epoch 76 - Training Loss: 0.6902, Validation Loss: 0.6831
Epoch 77 - Training Loss: 0.6525, Validation Loss: 0.6944
Epoch 78 - Training Loss: 0.6768, Validation Loss: 0.6883
Epoch 79 - Training Loss: 0.6645, Validation Loss: 0.6904
Epoch 80 - Training Loss: 0.6707, Validation Loss: 0.9187
Epoch 81 - Training Loss: 0.9407, Validation Loss: 0.9243
Epoch 82 - Training Loss: 0.9329, Validation Loss: 0.9204
Epoch 83 - Training Loss: 0.9052, Validation Loss: 0.9184
Epoch 84 - Training Loss: 0.8956, Validation Loss: 0.9283
Epoch 85 - Training Loss: 0.9226, Validation Loss: 0.9237
Epoch 86 - Training Loss: 0.9269, Validation Loss: 0.9074
Epoch 87 - Training Loss: 0.8326, Validation Loss: 0.6876
Epoch 88 - Training Loss: 0.6603, Validation Loss: 0.6907
Epoch 89 - Training Loss: 0.6995, Validation Loss: 0.6885
Epoch 90 - Training Loss: 0.6902, Validation Loss: 0.6845
Epoch 91 - Training Loss: 0.6811, Validation Loss: 0.6898
Epoch 92 - Training Loss: 0.6719, Validation Loss: 0.6870
Epoch 93 - Training Loss: 0.6901, Validation Loss: 0.6936
Epoch 94 - Training Loss: 0.6900, Validation Loss: 0.6882
Epoch 95 - Training Loss: 0.6808, Validation Loss: 0.6894
Epoch 96 - Training Loss: 0.6899, Validation Loss: 0.6867
Epoch 97 - Training Loss: 0.6807, Validation Loss: 0.6880
Epoch 98 - Training Loss: 0.6988, Validation Loss: 0.7012
Epoch 99 - Training Loss: 0.6805, Validation Loss: 0.6918
Epoch 100 - Training Loss: 0.6895, Validation Loss: 0.6851
Epoch 101 - Training Loss: 0.6984, Validation Loss: 0.6877
Epoch 102 - Training Loss: 0.6892, Validation Loss: 0.6838
Epoch 103 - Training Loss: 0.7074, Validation Loss: 0.6864
Epoch 104 - Training Loss: 0.6798, Validation Loss: 0.6916
Epoch 105 - Training Loss: 0.6979, Validation Loss: 0.6823
Epoch 106 - Training Loss: 0.6795, Validation Loss: 0.6903
Epoch 107 - Training Loss: 0.6976, Validation Loss: 0.6916
Epoch 108 - Training Loss: 0.7157, Validation Loss: 0.6863
Epoch 109 - Training Loss: 0.6883, Validation Loss: 0.6836
Epoch 110 - Training Loss: 0.6881, Validation Loss: 0.6796
Epoch 111 - Training Loss: 0.7062, Validation Loss: 0.6876
Epoch 112 - Training Loss: 0.7062, Validation Loss: 0.6889
Epoch 113 - Training Loss: 0.6970, Validation Loss: 0.6836
Epoch 114 - Training Loss: 0.7060, Validation Loss: 0.6902
Epoch 115 - Training Loss: 0.6877, Validation Loss: 0.6889
Epoch 116 - Training Loss: 0.6786, Validation Loss: 0.6862
Epoch 117 - Training Loss: 0.6876, Validation Loss: 0.6849
Epoch 118 - Training Loss: 0.6967, Validation Loss: 0.6982
Epoch 119 - Training Loss: 0.6785, Validation Loss: 0.6915
Epoch 120 - Training Loss: 0.6875, Validation Loss: 0.6796
Epoch 121 - Training Loss: 0.6784, Validation Loss: 0.6955
Epoch 122 - Training Loss: 0.6966, Validation Loss: 0.6782
Epoch 123 - Training Loss: 0.6783, Validation Loss: 0.6849
Epoch 124 - Training Loss: 0.6692, Validation Loss: 0.6928
Epoch 125 - Training Loss: 0.6874, Validation Loss: 0.6875
Epoch 126 - Training Loss: 0.6783, Validation Loss: 0.6902
Epoch 127 - Training Loss: 0.6783, Validation Loss: 0.6955
Epoch 128 - Training Loss: 0.6823, Validation Loss: 0.6875
Epoch 129 - Training Loss: 0.7056, Validation Loss: 0.6875
Epoch 130 - Training Loss: 0.6692, Validation Loss: 0.6942
Epoch 131 - Training Loss: 0.6874, Validation Loss: 0.6862
Epoch 132 - Training Loss: 0.7056, Validation Loss: 0.6889
Epoch 133 - Training Loss: 0.6873, Validation Loss: 0.6849
Epoch 134 - Training Loss: 0.6873, Validation Loss: 0.6875
Epoch 135 - Training Loss: 0.6782, Validation Loss: 0.6929
Epoch 136 - Training Loss: 0.7146, Validation Loss: 0.6928
Epoch 137 - Training Loss: 0.6872, Validation Loss: 0.6875
Epoch 138 - Training Loss: 0.6963, Validation Loss: 0.6902
Epoch 139 - Training Loss: 0.6962, Validation Loss: 0.6835
Epoch 140 - Training Loss: 0.6871, Validation Loss: 0.6849
Epoch 141 - Training Loss: 0.6779, Validation Loss: 0.6889
Epoch 142 - Training Loss: 0.6778, Validation Loss: 0.6849
Epoch 143 - Training Loss: 0.6869, Validation Loss: 0.6875
Epoch 144 - Training Loss: 0.6959, Validation Loss: 0.6915
Epoch 145 - Training Loss: 0.6776, Validation Loss: 0.6862
Epoch 146 - Training Loss: 0.6957, Validation Loss: 0.6875
Epoch 147 - Training Loss: 0.6929, Validation Loss: 0.6835
Epoch 148 - Training Loss: 0.6859, Validation Loss: 0.6875
Epoch 149 - Training Loss: 0.6672, Validation Loss: 0.6982
Epoch 150 - Training Loss: 0.6942, Validation Loss: 0.6823
Epoch 151 - Training Loss: 0.6666, Validation Loss: 0.6969
Epoch 152 - Training Loss: 0.7118, Validation Loss: 0.6863
Epoch 153 - Training Loss: 0.6842, Validation Loss: 0.6889
Epoch 154 - Training Loss: 0.6930, Validation Loss: 0.6930
Epoch 155 - Training Loss: 0.6835, Validation Loss: 0.6890
Epoch 156 - Training Loss: 0.6832, Validation Loss: 0.6930
Epoch 157 - Training Loss: 0.6819, Validation Loss: 0.6880
Epoch 158 - Training Loss: 0.6714, Validation Loss: 0.6923
Epoch 159 - Training Loss: 0.6699, Validation Loss: 0.6902
Epoch 160 - Training Loss: 0.6872, Validation Loss: 0.6936
Epoch 161 - Training Loss: 0.6864, Validation Loss: 0.6905
Epoch 162 - Training Loss: 0.6674, Validation Loss: 0.6835
Epoch 163 - Training Loss: 0.6755, Validation Loss: 0.6869
Epoch 164 - Training Loss: 0.6840, Validation Loss: 0.6880
Epoch 165 - Training Loss: 0.6739, Validation Loss: 0.6815
Epoch 166 - Training Loss: 0.6548, Validation Loss: 0.6888
Epoch 167 - Training Loss: 0.6809, Validation Loss: 0.6848
Epoch 168 - Training Loss: 0.6612, Validation Loss: 0.6912
Epoch 169 - Training Loss: 0.6511, Validation Loss: 0.6874
Epoch 170 - Training Loss: 0.6494, Validation Loss: 0.6837
Epoch 171 - Training Loss: 0.7300, Validation Loss: 0.9159
Epoch 172 - Training Loss: 0.9136, Validation Loss: 0.9231
Epoch 173 - Training Loss: 0.9331, Validation Loss: 0.9203
Epoch 174 - Training Loss: 0.9329, Validation Loss: 0.9294
Epoch 175 - Training Loss: 0.9235, Validation Loss: 0.9146
Epoch 176 - Training Loss: 0.9231, Validation Loss: 0.9237
Epoch 177 - Training Loss: 0.9411, Validation Loss: 0.9170
Epoch 178 - Training Loss: 0.9229, Validation Loss: 0.9249
Epoch 179 - Training Loss: 0.9228, Validation Loss: 0.9221
Epoch 180 - Training Loss: 0.9232, Validation Loss: 0.9194
Epoch 181 - Training Loss: 0.9136, Validation Loss: 0.9233
Epoch 182 - Training Loss: 0.9409, Validation Loss: 0.9232
Epoch 183 - Training Loss: 0.9318, Validation Loss: 0.9270
Epoch 184 - Training Loss: 0.9225, Validation Loss: 0.9200
Epoch 185 - Training Loss: 0.9036, Validation Loss: 0.9278
Epoch 186 - Training Loss: 0.9199, Validation Loss: 0.9261
Epoch 187 - Training Loss: 0.8919, Validation Loss: 0.9191
Epoch 188 - Training Loss: 0.9237, Validation Loss: 0.9081
Epoch 189 - Training Loss: 0.8560, Validation Loss: 0.6777
Epoch 190 - Training Loss: 0.6552, Validation Loss: 0.6889
Epoch 191 - Training Loss: 0.7053, Validation Loss: 0.6823
Epoch 192 - Training Loss: 0.7053, Validation Loss: 0.6822
Epoch 193 - Training Loss: 0.7137, Validation Loss: 0.6862
Epoch 194 - Training Loss: 0.6860, Validation Loss: 0.6888
Epoch 195 - Training Loss: 0.6858, Validation Loss: 0.6861
Epoch 196 - Training Loss: 0.6947, Validation Loss: 0.6848
Epoch 197 - Training Loss: 0.7128, Validation Loss: 0.6821
Epoch 198 - Training Loss: 0.6851, Validation Loss: 0.6861
Epoch 199 - Training Loss: 0.6849, Validation Loss: 0.6875
Epoch 200 - Training Loss: 0.6706, Validation Loss: 0.6967
Epoch 201 - Training Loss: 0.7029, Validation Loss: 0.6861
Epoch 202 - Training Loss: 0.6665, Validation Loss: 0.6914
Epoch 203 - Training Loss: 0.6753, Validation Loss: 0.6782
Epoch 204 - Training Loss: 0.6751, Validation Loss: 0.6848
Epoch 205 - Training Loss: 0.6926, Validation Loss: 0.6874
Epoch 206 - Training Loss: 0.6733, Validation Loss: 0.6941
Epoch 207 - Training Loss: 0.6810, Validation Loss: 0.6873
Epoch 208 - Training Loss: 0.7038, Validation Loss: 0.6827
Epoch 209 - Training Loss: 0.6562, Validation Loss: 0.6797
Epoch 210 - Training Loss: 0.6555, Validation Loss: 0.6828
Epoch 211 - Training Loss: 0.6820, Validation Loss: 0.6890
Epoch 212 - Training Loss: 0.6537, Validation Loss: 0.5679
Epoch 213 - Training Loss: 0.5733, Validation Loss: 0.6450
Epoch 214 - Training Loss: 0.5771, Validation Loss: 0.6388
Epoch 215 - Training Loss: 0.5995, Validation Loss: 0.6731
Epoch 216 - Training Loss: 0.6477, Validation Loss: 0.6755
Epoch 217 - Training Loss: 0.6719, Validation Loss: 0.6793
Epoch 218 - Training Loss: 0.6859, Validation Loss: 0.6796
Epoch 219 - Training Loss: 0.6649, Validation Loss: 0.6843
Epoch 220 - Training Loss: 0.6449, Validation Loss: 0.6765
Epoch 221 - Training Loss: 0.6301, Validation Loss: 0.5966
Epoch 222 - Training Loss: 0.5813, Validation Loss: 0.6790
Epoch 223 - Training Loss: 0.6704, Validation Loss: 0.6872
Epoch 224 - Training Loss: 0.6952, Validation Loss: 0.6812
Epoch 225 - Training Loss: 0.6687, Validation Loss: 0.6841
Epoch 226 - Training Loss: 0.6776, Validation Loss: 0.6837
Epoch 227 - Training Loss: 0.6680, Validation Loss: 0.6940
Epoch 228 - Training Loss: 0.6765, Validation Loss: 0.6883
Epoch 229 - Training Loss: 0.6579, Validation Loss: 0.6863
Epoch 230 - Training Loss: 0.6756, Validation Loss: 0.6814
Epoch 231 - Training Loss: 0.6845, Validation Loss: 0.6875
Epoch 232 - Training Loss: 0.6838, Validation Loss: 0.6878
Epoch 233 - Training Loss: 0.6926, Validation Loss: 0.6760
Epoch 234 - Training Loss: 0.6833, Validation Loss: 0.6772
Epoch 235 - Training Loss: 0.6741, Validation Loss: 0.6804
Epoch 236 - Training Loss: 0.6741, Validation Loss: 0.6767
Epoch 237 - Training Loss: 0.6649, Validation Loss: 0.6782
Epoch 238 - Training Loss: 0.6649, Validation Loss: 0.6751
Epoch 239 - Training Loss: 0.6740, Validation Loss: 0.6788
Epoch 240 - Training Loss: 0.6739, Validation Loss: 0.6845
Epoch 241 - Training Loss: 0.6557, Validation Loss: 0.6722
Epoch 242 - Training Loss: 0.6738, Validation Loss: 0.6744
Epoch 243 - Training Loss: 0.6828, Validation Loss: 0.6731
Epoch 244 - Training Loss: 0.6733, Validation Loss: 0.6734
Epoch 245 - Training Loss: 0.6726, Validation Loss: 0.6793
Epoch 246 - Training Loss: 0.6989, Validation Loss: 0.6752
Epoch 247 - Training Loss: 0.6588, Validation Loss: 0.6828
Epoch 248 - Training Loss: 0.6833, Validation Loss: 0.6740
Epoch 249 - Training Loss: 0.6735, Validation Loss: 0.6827
Epoch 250 - Training Loss: 0.6574, Validation Loss: 0.6787
Epoch 251 - Training Loss: 0.5750, Validation Loss: 0.5050
Epoch 252 - Training Loss: 0.5185, Validation Loss: 0.4928
Epoch 253 - Training Loss: 0.5191, Validation Loss: 0.5046
Epoch 254 - Training Loss: 0.5423, Validation Loss: 0.5333
Epoch 255 - Training Loss: 0.5845, Validation Loss: 0.4951
Epoch 256 - Training Loss: 0.5200, Validation Loss: 0.5057
Epoch 257 - Training Loss: 0.5286, Validation Loss: 0.5032
Epoch 258 - Training Loss: 0.6320, Validation Loss: 0.6789
Epoch 259 - Training Loss: 0.6821, Validation Loss: 0.6839
Epoch 260 - Training Loss: 0.6644, Validation Loss: 0.6755
Epoch 261 - Training Loss: 0.6913, Validation Loss: 0.6810
Epoch 262 - Training Loss: 0.6546, Validation Loss: 0.6767
Epoch 263 - Training Loss: 0.6636, Validation Loss: 0.6803
Epoch 264 - Training Loss: 0.6541, Validation Loss: 0.6792
Epoch 265 - Training Loss: 0.6575, Validation Loss: 0.6771
Epoch 266 - Training Loss: 0.6021, Validation Loss: 0.7637
Epoch 267 - Training Loss: 0.8967, Validation Loss: 0.9064
Epoch 268 - Training Loss: 0.9314, Validation Loss: 0.9114
Epoch 269 - Training Loss: 0.9254, Validation Loss: 0.9223
Epoch 270 - Training Loss: 0.9164, Validation Loss: 0.9196
Epoch 271 - Training Loss: 0.9160, Validation Loss: 0.9116
Epoch 272 - Training Loss: 0.9155, Validation Loss: 0.9141
Epoch 273 - Training Loss: 0.8983, Validation Loss: 0.9203
Epoch 274 - Training Loss: 0.9055, Validation Loss: 0.9124
Epoch 275 - Training Loss: 0.9324, Validation Loss: 0.9165
Epoch 276 - Training Loss: 0.9409, Validation Loss: 0.9108
Epoch 277 - Training Loss: 0.9221, Validation Loss: 0.9078
Epoch 278 - Training Loss: 0.9126, Validation Loss: 0.9077
Epoch 279 - Training Loss: 0.9214, Validation Loss: 0.9143
Epoch 280 - Training Loss: 0.9303, Validation Loss: 0.9077
Epoch 281 - Training Loss: 0.9120, Validation Loss: 0.9090
Epoch 282 - Training Loss: 0.8972, Validation Loss: 0.9196
Epoch 283 - Training Loss: 0.9036, Validation Loss: 0.9170
Epoch 284 - Training Loss: 0.9118, Validation Loss: 0.9037
Epoch 285 - Training Loss: 0.9117, Validation Loss: 0.9117
Epoch 286 - Training Loss: 0.9023, Validation Loss: 0.9103
Epoch 287 - Training Loss: 0.9199, Validation Loss: 0.9050
Epoch 288 - Training Loss: 0.9286, Validation Loss: 0.9116
Epoch 289 - Training Loss: 0.9104, Validation Loss: 0.9036
Epoch 290 - Training Loss: 0.8921, Validation Loss: 0.9116
Epoch 291 - Training Loss: 0.8831, Validation Loss: 0.9062
Epoch 292 - Training Loss: 0.9012, Validation Loss: 0.9062
Epoch 293 - Training Loss: 0.9103, Validation Loss: 0.9115
Epoch 294 - Training Loss: 0.9194, Validation Loss: 0.9142
Epoch 295 - Training Loss: 0.9285, Validation Loss: 0.9089
Epoch 296 - Training Loss: 0.9193, Validation Loss: 0.8995
Epoch 297 - Training Loss: 0.8828, Validation Loss: 0.9181
Epoch 298 - Training Loss: 0.8916, Validation Loss: 0.9087
Epoch 299 - Training Loss: 0.9188, Validation Loss: 0.9059
Epoch 300 - Training Loss: 0.9180, Validation Loss: 0.9110
Test predictions saved to C:\Users\didsu\code_projects\uni_24\DL\link_dl\_02_homeworks\homework_2\test_predictions_ELU_testing_almost_final.csv
Test predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
